{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**1.What is Simple Linear Regression?**\n",
        "\n",
        "**Ans-**Simple Linear Regression is a fundamental algorithm in machine learning used for predictive modeling. It establishes a relationship between two variables:\n",
        "\n",
        "Independent Variable (X) - The predictor or input variable.\n",
        "\n",
        "Dependent Variable (Y) - The response or output variable.\n",
        "\n",
        "The goal is to find a linear relationship between xX and ùëå\n",
        "Y, which is represented using the equation:\n",
        "\n",
        "ùëå=ùëöùëã+ùëè\n",
        "\n",
        "Y=mX+b"
      ],
      "metadata": {
        "id": "qQDFNXMkuEGB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2- What are the key assumptions of Simple Linear Regression.**\n",
        "\n",
        "**Ans-** Key Assumptions of Simple Linear Regression-\n",
        "\n",
        "*   **Linearity**\n",
        "\n",
        "*  The relationship between the independent variable (xX) and the\n",
        "dependent variable (yY) should be linear.\n",
        "*  This means that changes in xX should lead to proportional changes in yY.\n",
        "\n",
        "*   **Independence**\n",
        "*  The observations should be independent of each other.\n",
        "\n",
        "*  There should be no correlation between the residuals (errors in prediction).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xNI5xkcYv3Qa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3- What does the coefficient m represent in the equation Y=mX+c?**\n",
        "\n",
        "**Ans-** m= slope (coffiecient of X)."
      ],
      "metadata": {
        "id": "G7WG2k15z7jg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.What does the intercept c represent in the equation Y=mX+c?**\n",
        "\n",
        "**Ans-**In the equation Y=ùëöùëã+c the intercept c represents the Y-intercept of the line."
      ],
      "metadata": {
        "id": "vs6QZTgZ01fp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.How do we calculate the slope m in Simple Linear Regression?**\n",
        "\n",
        "**Ans-** In Simple Linear Regression, the slope ùëö  (also called the regression coefficient) is calculated using the formula:\n",
        "\n",
        "            "
      ],
      "metadata": {
        "id": "8kNWXWTx30XN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. What is the purpose of the least squares method in Simple Linear Regression?**\n",
        "\n",
        "**Ans-**  The least squares method in Simple Linear Regression is used to find the best-fitting line that minimizes the error between the predicted values and the actual data points."
      ],
      "metadata": {
        "id": "ZY-qAMj54lBM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7.  How is the coefficient of determination (R¬≤) interpreted in Simple Linear Regression?**\n",
        "\n",
        "**Ans-** The coefficient of determination (R2) is a statistical measure that indicates how well the independent variable (X) explains the variability of the dependent variable (Y) in a Simple Linear Regression model."
      ],
      "metadata": {
        "id": "y9XEq8_M43s1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. What is Multiple Linear Regression?**\n",
        "\n",
        "**Ans-** Multiple Linear Regression (MLR) is an extension of Simple Linear Regression, where multiple independent variables (X1,X2,X3 ,...) are used to predict a dependent variable (Y). It helps analyze the relationship between one dependent variable and two or more independent variable."
      ],
      "metadata": {
        "id": "BcIGOgqB6Nce"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9.What is the main difference between Simple and Multiple Linear Regression?**\n",
        "\n",
        "**Ans-** The primary difference between Simple Linear Regression (SLR) and Multiple Linear Regression (MLR) is the number of independent variables used to predict the dependent variable."
      ],
      "metadata": {
        "id": "tn06eieG6wWs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10.What are the key assumptions of Multiple Linear Regression?**\n",
        "\n",
        "**Ans-** Key Assumptions of Multiple Linear Regression (MLR)-\n",
        " *   Linearity\n",
        " *   Independence of Errors\n",
        " *   No Multicollinearity\n",
        " *   Normality of Residuals"
      ],
      "metadata": {
        "id": "pYuLWth87Orm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**11.  What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model?**\n",
        "\n",
        "**Ans-** Heteroscedasticity refers to a situation in which the variance of residuals (errors) is not constant across all levels of the independent variables in a Multiple Linear Regression model.\n",
        "\n",
        "Heteroscedasticity Affect Regression Results-\n",
        "\n",
        "*  **Biased Standard Errors ‚Üí** This leads to incorrect hypothesis tests.\n",
        "\n",
        "*  **Inefficient Estimates ‚Üí** The regression model no longer provides the best linear unbiased estimates.\n",
        "\n",
        "*  Overconfidence or Underconfidence in Predictions."
      ],
      "metadata": {
        "id": "2An83fe58C4F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**12. How can you improve a Multiple Linear Regression model with high multicollinearity?**\n",
        "\n",
        "**Ans-** Multicollinearity occurs when two or more independent variables (X1,X2,X3,...) in a Multiple Linear Regression (MLR) model are highly correlated, making it difficult to determine their individual effects on the dependent variable (Y). This can lead to unstable coefficient estimates and misleading statistical inferences.\n",
        "\n"
      ],
      "metadata": {
        "id": "eUZRaVMX9Kk3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**13. What are some common techniques for transforming categorical variables for use in regression models?**\n",
        "\n",
        "**Ans-** Common Techniques for Transforming Categorical Variables for Regression Models-\n",
        "\n",
        "*  One-Hot Encoding\n",
        "*   Label Encoding\n",
        "*  Ordinal Encoding\n",
        "*  Frequency Encoding\n",
        "*  Target Encoding\n",
        "*  Binary Encoding\n"
      ],
      "metadata": {
        "id": "geMpot-j9xo9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**14.What is the role of interaction terms in Multiple Linear Regression?**\n",
        "\n",
        "**Ans-** Interaction terms in Multiple Linear Regression allow us to model the combined effect of two or more independent variables on the dependent variable Y, beyond their individual effects. These terms are particularly useful when you suspect that the effect of one predictor on Y may change depending on the value of another predictor."
      ],
      "metadata": {
        "id": "5aRAyyB8-ZIV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**15.How can the interpretation of intercept differ between Simple and Multiple Linear Regression?**\n",
        "\n",
        "**Ans-** he intercept in regression models (c) is the value of the dependent variable (Y) when all independent variables (X1,X2..,Xn) are set to zero. While the mathematical definition remains the same in both Simple Linear Regression (SLR) and Multiple Linear Regression (MLR), the interpretation of the intercept differs due to the complexity of the relationships in each model."
      ],
      "metadata": {
        "id": "BZ8WEE2E-rmM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**16. What is the significance of the slope in regression analysis, and how does it affect predictions?**\n",
        "\n",
        "**Ans-**  Significance of the Slope in Regression Analysis and Its Impact on Predictions-\n",
        "\n",
        "*  Meaning of the Slope in Regression Analysis\n",
        "*  Slope in Multiple Linear Regression\n",
        "*  How the Slope Affects Predictions\n",
        "*  Statistical Significance of the Slope\n",
        "*  Common Pitfalls and Misinterpretations of the Slope"
      ],
      "metadata": {
        "id": "rF-zo4H0_L6s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**17.How does the intercept in a regression model provide context for the relationship between variables?**\n",
        "\n",
        "Ans- The intercept in a regression model represents the expected value of the dependent variable (Y) when all independent variables (X) are equal to zero. While its mathematical meaning is straightforward, its interpretation and significance depend on the context of the data.\n",
        "\n",
        "*   Understanding the Intercept in Different Types of Regression\n",
        "*  The Contextual Role of the Intercept\n",
        "*  How the Intercept Helps Understand Relationships Between Variables\n",
        "*  Adjusting the Intercept for Better Interpretation\n"
      ],
      "metadata": {
        "id": "K3rqxSWRcbix"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**18.What are the limitations of using R¬≤ as a sole measure of model performance?**\n",
        "\n",
        "Ans- The coefficient of determination (R2 ) is a common metric for evaluating regression models. It measures the proportion of variance in the dependent variable (Y) explained by the independent variables (X). However, relying solely on R2 to assess model performance has several limitations:\n",
        "\n",
        "* R2 Does Not Indicate Model Accuracy\n",
        "* R2 Does Not Detect Overfitting\n",
        "* R2 Does Not Assess Model Validity\n",
        "* R2 Ignores Bias and Predictive Power\n"
      ],
      "metadata": {
        "id": "mH_ceayidgj5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**19.How would you interpret a large standard error for a regression coefficient?**\n",
        "\n",
        "**Ans-** In a regression model, the standard error (SE) of a coefficient measures the variability or uncertainty in estimating that coefficient. A large standard error suggests that the estimated coefficient is unstable and less reliable.\n"
      ],
      "metadata": {
        "id": "nuXhJ20he-YB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**20.How can heteroscedasticity be identified in residual plots, and why is it important to address it?**\n",
        "\n",
        "**Ans-** Heteroscedasticity occurs when the variance of residuals (errors) is not constant across all levels of the independent variable(s). This violates a key assumption of Ordinary Least Squares (OLS) regression, which assumes homoscedasticity (constant variance).\n",
        "\n",
        "If heteroscedasticity is present, the model‚Äôs predictions become less reliable, and statistical inferences (e.g., confidence intervals, hypothesis tests) may be invalid.\n",
        "\n"
      ],
      "metadata": {
        "id": "il1YSw3Kfcdx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**21. What does it mean if a Multiple Linear Regression model has a high R¬≤ but low adjusted R¬≤?**\n",
        "\n",
        "**Ans-** If a Multiple Linear Regression model has a high R2 but a low adjusted R2, it typically indicates that some independent variables do not contribute significantly to explaining the dependent variable."
      ],
      "metadata": {
        "id": "g2cWVG2hf4lA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**22.Why is it important to scale variables in Multiple Linear Regression?**\n",
        "\n",
        "**Ans-** Scaling variables is an essential step in Multiple Linear Regression (MLR), especially when the independent variables have vastly different magnitudes. Although OLS regression does not inherently require scaling (unlike models like logistic regression or SVMs), there are several key reasons why scaling can improve regression analysis.\n",
        "\n"
      ],
      "metadata": {
        "id": "UEYNdzYRjFvK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**23. What is polynomial regression?**\n",
        "\n",
        "**Ans-** Polynomial Regression is an extension of Linear Regression that models the relationship between the independent variable(s) and the dependent variable as an n-degree polynomial rather than a straight line."
      ],
      "metadata": {
        "id": "n5W4OEpIkQSz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**24.How does polynomial regression differ from linear regression?**\n",
        "\n",
        "**Ans-**  Polynomial Regression and Linear Regression are both types of regression analysis used to model relationships between variables, but they differ in how they model these relationships.\n",
        "\n",
        "*  Nature of the Relationship\n",
        "*  Input Features\n",
        "*  Complexity"
      ],
      "metadata": {
        "id": "qBHHmLQHkn7R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**25.When is polynomial regression used?**\n",
        "\n",
        "**Ans-** Polynomial Regression is used when the relationship between the independent variable(s) and the dependent variable is non-linear, but can still be modeled using polynomial terms of the independent variables."
      ],
      "metadata": {
        "id": "rAl_ZyuYlnDy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**26.What is the general equation for polynomial regression?**\n",
        "\n",
        "**Ans-**The general equation for Polynomial Regression is an extension of the Linear Regression equation, where the independent variable X is raised to higher powers (e.g., X2,X3,) to capture non-linear relationships between the independent and dependent variables."
      ],
      "metadata": {
        "id": "KUrfOqXyl3qL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**27.Can polynomial regression be applied to multiple variables?**\n",
        "\n",
        "**Ans-** Yes, Polynomial Regression can be applied to multiple variables, and this is known as Multivariable Polynomial Regression."
      ],
      "metadata": {
        "id": "Rl8F8otmmpAi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**28.What are the limitations of polynomial regression?**\n",
        "\n",
        "**Ans-** Limitations of Polynomial Regression-\n",
        "*   Overfitting with Higher-Degree Polynomials\n",
        "*   Increased Model Complexity\n",
        "*  Multicollinearity\n",
        "*  Extrapolation Risk\n",
        "*   Sensitivity to Outliers"
      ],
      "metadata": {
        "id": "zUKuHIHlm4Up"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**29. What methods can be used to evaluate model fit when selecting the degree of a polynomial?**\n",
        "\n",
        "**Ans-** When selecting the degree of a polynomial for polynomial regression, it's crucial to evaluate model fit to ensure that the chosen degree strikes the right balance between underfitting and overfitting. Several methods can help you assess the model's performance and choose the optimal polynomial degree.\n",
        "\n",
        "*  Cross-Validation\n",
        "*  Plotting the Learning Curve\n",
        "*  Train-Test Split\n",
        "*  Adjust R2\n"
      ],
      "metadata": {
        "id": "9ojCWhZ8nXuS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**30.Why is visualization important in polynomial regression?**\n",
        "\n",
        "**Ans-** Visualization plays a crucial role in polynomial regression because it helps in understanding the relationship between the independent and dependent variables, and it provides insights into the model‚Äôs behavior.\n",
        "          several reasons why visualization is important:\n",
        "\n",
        "* Assessing the Relationship Between Variables\n",
        "*  Selecting the Optimal Polynomial Degree\n",
        "*  Identifying Data Issues or Patterns\n",
        "* Understanding the Model Fit\n",
        "\n"
      ],
      "metadata": {
        "id": "7ufq8jJkqAlE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**31.How is polynomial regression implemented in Python?**\n",
        "\n",
        "**Ans-** Polynomial regression is relatively straightforward to implement in Python using libraries like NumPy for mathematical operations and scikit-learn for modeling. Below is a step-by-step guide to implementing polynomial regression."
      ],
      "metadata": {
        "id": "sUK135IKqhrh"
      }
    }
  ]
}